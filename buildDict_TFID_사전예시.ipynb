{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNwsWWfzr+M7htJ1vpKBIZZ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"vNCRfG7BwmSB"},"outputs":[],"source":["#사전 구축 함수수\n","from nltk import FreqDist\n","import numpy as np\n","import re\n","\n","def buildDict(docs):\n","    doc_tokens = []     # python list\n","    for doc in docs:\n","        delim = re.compile(r'[\\s,.]+')\n","        tokens = delim.split(doc.lower()) \n","        if tokens[-1] == '' :   tokens = tokens[:-1] \n","        doc_tokens.append(tokens)\n","\n","        \n","    vocab = FreqDist(np.hstack(doc_tokens))\n","    vocab = vocab.most_common()\n","    word_to_id = {word[0] : id for id, word in enumerate(vocab)}\n","    id_to_word = {id : word[0] for id, word in enumerate(vocab)}\n","    return doc_tokens, vocab, word_to_id, id_to_word"]},{"cell_type":"code","source":["#TFID 함수 \n","from collections import Counter\n","import math\n","import numpy as np\n","\n","def TFIDF(doc_tokens, id_to_word, word_to_id):\n","    tf_vectors = []\n","    idf = {}\n","\n","    #TF 구하기\n","    for doc in doc_tokens:\n","        vec = [0.0 for _ in range((len(id_to_word)))]\n","        word_count = Counter(doc)\n","        for key, value in word_count.items():\n","            vec[word_to_id[key]] = 1+ math.log2(value) #tf계산\n","        tf_vectors.append(vec)\n","    \n","    #IDF 구하기\n","    for id, _ in id_to_word.items():\n","        idf[id] = 0.0\n","        for doc in tf_vectors:\n","            if doc[id] > 0:\n","                idf[id] += 1\n","    N = len(tf_vectors)            \n","    idf = {id : math.log2(N/val) for id, val in idf.items()}\n","\n","    #TF-IDF 구하기\n","    idf_list = [val for _, val in idf.items()]\n","    tfidf = np.array([np.multiply(tf, idf_list) for tf in tf_vectors])\n","\n","    return tf_vectors, idf, tfidf"],"metadata":{"id":"do68JVcNw20u"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["docs = []\n","docs.append('To do is to be. To be is to do.')\n","docs.append('To be or not to be. I am what I am')\n","docs.append('I think therefore I am. Do be do be do.')\n","docs.append('Do do do da da da. Let it be let it be.')\n","\n","doc_tokens, vocab, word_to_id, id_to_word = buildDict(docs)\n","tf_vectors, idf, tfidf = TFIDF(doc_tokens, id_to_word, word_to_id)"],"metadata":{"id":"Nxg6oBFvwtg-"},"execution_count":null,"outputs":[]}]}
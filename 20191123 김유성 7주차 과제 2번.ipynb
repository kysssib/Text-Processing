{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP8sgkwix3umu3TR5NjYmMK"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gEY7e5pmGuSJ","executionInfo":{"status":"ok","timestamp":1681551532897,"user_tz":-540,"elapsed":4,"user":{"displayName":"김유성 (Kuru)","userId":"06118974840308071375"}},"outputId":"ef7a1fbd-bf82-4b5e-e43f-717d15f790a5"},"outputs":[{"output_type":"stream","name":"stdout","text":["10번 문서와  8번 문서의 코사인 유사도가 33.73%로 1번째로 유사합니다.\n"," 9번 문서와  8번 문서의 코사인 유사도가 30.11%로 2번째로 유사합니다.\n","13번 문서와  8번 문서의 코사인 유사도가 27.15%로 3번째로 유사합니다.\n"," 6번 문서와  5번 문서의 코사인 유사도가 24.88%로 4번째로 유사합니다.\n"," 9번 문서와 10번 문서의 코사인 유사도가 24.81%로 5번째로 유사합니다.\n"]}],"source":["with open('./sample_data/sample.txt', 'r') as f:\n","  docs = f.readlines()\n","#for id, doc in enumerate(docs):\n","  #print('[{}] : {}...'.format(id, doc[:30]))\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","\n","#tfidf 벡터 매트릭스 생성\n","tfidf = TfidfVectorizer()\n","tfidf_matrix = tfidf.fit_transform(docs)\n","#print('type of tfidf_matrix {}'.format(type(tfidf_matrix)))\n","#print('shape of tfidf_matrix {}'.format(tfidf_matrix.shape))\n","\n","vocab = sorted(tfidf.vocabulary_.items())\n","#vocab[10:20]\n","\n","import pandas as pd\n","\n","df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n","#print(df.head(5))\n","\n","tfidf_table = tfidf_matrix.toarray()\n","\n","keywords = []\n","for weight in tfidf_table:\n","  w_vec = list(enumerate(weight))\n","  w_vec = sorted(w_vec, key=lambda x : x[1], reverse=True)\n","  #print(w_vec[:3])\n","  keywords.append(w_vec)\n","\n","import numpy as np\n","def tfidf_rank(tfidf_matrix):\n","  rank = []\n","  avg, stddev = 0.0, 0.0\n","  #문서 별 tfidf 가중치의 합 계산 : (문서id, 가중치 합)\n","  for idx, tfidf in enumerate(tfidf_matrix):\n","    rank.append((idx, tfidf.sum()))\n","    \n","  #가중치의 합이 높은 문서 순으로 정렬\n","  rank.sort(key=lambda x : x[1], reverse=True)\n","  #tfidf의 평균과 표준편차 계산\n","  tfidf_sum = [tfidf.sum() for tfidf in tfidf_matrix]\n","  avg = np.mean(tfidf_sum)\n","  stddev = np.std(tfidf_sum)\n","  return rank, avg, stddev\n","\n","rank, avg, stddev = tfidf_rank(tfidf_matrix)\n","\n","#print(rank[:2])\n","#print('avg = {}, stddev = {}'.format(avg, stddev))\n","\n","df = pd.DataFrame(tfidf_matrix.toarray(), columns=tfidf.get_feature_names_out())\n","result = df.sum()\n","result = result.sort_values(ascending=False)\n","#print(result[:10])\n","\n","tfidf2 = TfidfVectorizer(stop_words='english')\n","tfidf_matrix2 = tfidf2.fit_transform(docs)\n","#print('shape of tfidf_matrix2 = {}'.format(tfidf_matrix2.shape))\n","df = pd.DataFrame(tfidf_matrix2.toarray(), columns=tfidf2.get_feature_names_out())\n","result = df.sum()\n","result = result.sort_values(ascending=False)\n","#print(result[:10])\n","\n","#과제 2번\n","from sklearn.metrics.pairwise import cosine_similarity\n","from sklearn.metrics.pairwise import linear_kernel\n","\n","from functools import reduce\n","\n","cos_sim = cosine_similarity(tfidf_matrix, tfidf_matrix)\n","\n","rank5 = {0:[0,0]}\n","for i, data in enumerate(cos_sim):\n","  for j, doc in enumerate(data):\n","    seconddata = doc\n","    sortkeys = sorted(rank5.keys())\n","    #print(sortkeys,len(sortkeys))\n","    if doc < 0.9:\n","      if min(rank5.keys())<doc:\n","        rank5[doc] = [i,j]\n","      if len(rank5.keys()) > 5:\n","        del rank5[sortkeys[0]]\n","#print(rank5)\n","rank5 = dict(sorted(rank5.items(), reverse=True))\n","cnt = 1\n","for key,value in rank5.items():\n","  print(\"{0:2d}번 문서와 {1:2d}번 문서의 코사인 유사도가 {2:0.02f}%로 {3}번째로 유사합니다.\".format(value[0],value[1],key*100,cnt))\n","  cnt += 1"]}]}